---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a researcher on the [interpretability team](https://transformer-circuits.pub/) at [Anthropic](https://www.anthropic.com/) where I try to reverse engineer how language models compose microscopic building blocks into higher level computational circuits.

<!-- I am a third year PhD student researching language model interpretability at the MIT ORC advised by [Dimitris Bertsimas](https://www.dbertsim.mit.edu/). I am interested in developing a mechanistic understanding of neural networks and using this to better monitor, control, and align advanced AI systems. I am fortunate to also collaborate with [Neel Nanda](https://www.neelnanda.io/about) and [Max Tegmark](https://tegmark.org/) and am graciously supported by an Open Philanthropy early career grant. -->

I completed my PhD at MIT where I worked with [Dimitris Bertsimas](https://www.dbertsim.mit.edu/), [Max Tegmark](https://tegmark.org/), and [Neel Nanda](https://www.neelnanda.io/about) on interpretability. Before that, I was a software engineer at Google working on data pipelines for the storage analytics team, and researched fairness-optimized political redistricting with [David Shmoys](https://people.orie.cornell.edu/shmoys/).

## Selected Publications
See [Google Scholar](https://scholar.google.com/citations?hl=en&user=5sxXSfwAAAAJ&view_op=list_works) for a full and up-to-date list.

* **Refusal in Language Models is Mediated by a Single Direction** <br>by Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, *Wes Gurnee*, Neel Nanda <br>Appeared at NeurIPS 2024 [[arXiv]](https://arxiv.org/pdf/2406.11717)
* **Not All Language Model Features are Linear** <br>by Joshua Engels, Eric J Michaud, Isaac Liao, *Wes Gurnee*, Max Tegmark <br>Appearing at ICLR 2025 [[arXiv]](https://arxiv.org/abs/2405.14860)
* **Confidence Regulation Neurons in Language Models** <br>by Alessandro Stolfo, Ben Wu, *Wes Gurnee*, Yonatan Belinkov, Xingyi Song, Mrinmaya Sachan, Neel Nanda <br>Appeared at NeurIPS 2024 [[arXiv]](https://arxiv.org/pdf/2406.16254)
* **Universal Neurons in GPT2 Language Models** <br>by *Wes Gurnee*, Theo Horsley, Zifan Carl Guo, Tara Rezaei Kheirkhah, Qinyi Sun, Will Hathaway, Neel Nanda, Dimitris Bertsimas <br>Published in TMLR [[arXiv]](https://arxiv.org/abs/2401.12181) [[Twitter]](https://twitter.com/wesg52/status/1749829624933322886)
* **Language Models Represent Space and Time** <br> by *Wes Gurnee* and Max Tegmark. <br>Appeared at ICLR 2024 [[arXiv]](https://arxiv.org/abs/2310.02207) [[Twitter]](https://twitter.com/wesg52/status/1709551516577902782)
* **Finding Neurons in a Haystack: Case Studies with Sparse Probing** <br>by *Wes Gurnee*, Neel Nanda, Matthew Pauly, Katherine Harvey, Dimitrii Troitskii, and Dimitris Bertsimas <br>Published in TMLR [[Paper]](https://openreview.net/pdf?id=JYs1R9IMJr) [[arXiv]](https://arxiv.org/abs/2305.01610) [[Twitter]](https://twitter.com/wesg52/status/1653750337373880322)
* **Learning Sparse Nonlinear Dynamics via Mixed-Integer Optimization** <br>by *Wes Gurnee* and Dimitris Bertsimas. <br>Published in *Nonlinear Dynamics* [[Paper]](https://rdcu.be/dBm3R)  [[arXiv]](https://arxiv.org/abs/2206.00176) [[Twitter]](https://twitter.com/wesg52/status/1536397919254892546)
* **Combatting gerrymandering with social choice: The design of multi-member districts** <br>by Nikhil Garg, *Wes Gurnee*, David Rothschild, David Shmoys <br>Published in EC '22 [[Paper]](https://dl.acm.org/doi/abs/10.1145/3490486.3538254)  [[arXiv]](https://arxiv.org/abs/2107.07083) [[Talk]](https://www.youtube.com/watch?v=ciD4ZelNgRk)
* **Fairmandering: A column generation heuristic for fairness-optimized political districting** <br>by *Wes Gurnee* and David Shmoys <br> Best paper award at SIAM ACDA '21 [[Paper]](https://epubs.siam.org/doi/pdf/10.1137/1.9781611976830.9)  [[arXiv]](https://arxiv.org/abs/2103.11469) [[Talk]](https://mediaspace.bucknell.edu/media/Fairmandering+Generating+Fairness+optimized+Political+Districts+-+Wes+Gurnee%2C+MIT%2C+11+11+2021/1_yu6gcqsm/185503823)

## Other Projects and Writing

* [SAE reconstruction errors are (empirically) pathological](https://www.lesswrong.com/posts/rZPiuFxESMxCDHe4B/sae-reconstruction-errors-are-empirically-pathological) (2024) - A preliminary research post on a potential issue with sparse autoencoder reconstructions.
* [Inductive Biases of SGD Training](/files/sgd_biases.pdf) (2022) - A review of inductive biases of stochastic gradient descent (SGD) when training deep neural network.
* [Analytics for Health Security](https://docs.google.com/document/d/14qh-eecQ1idLhH3vPWQXY2K71UURFKCxvjxdAgLuWaQ/edit?usp=sharing) (2022) - An analytics enabled defense-in-depth strategy for health security.
* [Optimal Political Districting: The Anchor Method](/files/anchor_method.pdf) (2022) - A formulation of optimal political districting using the anchor method.
* [Fairmandering: Generating Fairness-optimized Political Districts](https://www.siam.org/publications/siam-news/articles/fairmandering-generating-fairness-optimized-political-districts/) (SIAM News; 2021)
* [Scalable Approximation of k-medians for Political Districting](/files/Kmedians.pdf) (2020) - Using a linear programming relaxation to approximate the k-medians problem for political districting.
